# -*- coding: utf-8 -*-
"""AI_Powered_RFP_Response_Generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17wc7BbsZLQPApbdFnyLIJ2Rc-4mnyhuc
"""

!pip install llama-parse llama_index nltk openai

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

import nest_asyncio
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document, StorageContext, get_response_synthesizer, PromptTemplate
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core.extractors import TitleExtractor
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.ingestion import IngestionPipeline, IngestionCache
import nltk
import openai
import json
from llama_parse import LlamaParse
import os
from google.colab import drive
import nest_asyncio
import nltk

# Mount Google Drive
drive.mount('/content/drive')

# Specify the folder in Google Drive where your files are stored
destination_folder = '/content/drive/MyDrive'

# Apply nest_asyncio to allow nested event loops
nest_asyncio.apply()

# Download NLTK data
nltk.download('punkt')

# Initialize LlamaParse
parser = LlamaParse(
    api_key='llx-DDZFBCLXJTOpNO7h17MRrYvu5KvAet68HGnWavh4glLxp1Wi',
    result_type="markdown",
    num_workers=4,
    verbose=True,
    language="en"
)

# Initialize OpenAI API key
openai.api_key = 'open_ai_key'

# Function to load and parse documents
def load_documents(paths, label):
    documents = []
    for path in paths:
        parsed_docs = parser.load_data(path)
        documents.extend([Document(text=doc.text, metadata={label: path.split('/')[-1]}) for doc in parsed_docs])
    return documents

# List all files in the destination folder
all_files = [os.path.join(destination_folder, f) for f in os.listdir(destination_folder)]

# Filter files that contain "RFP", "Response", or "Q&A" in their title
filtered_files = [f for f in all_files if any(keyword in os.path.basename(f) for keyword in ['RFP', 'Response', 'Q&A'])]

# Separate RFP and Response documents
rfp_paths = [f for f in filtered_files if 'RFP' or 'Q&A' in os.path.basename(f)]
response_paths = [f for f in filtered_files if 'Response' in os.path.basename(f)]

# Load and parse the documents
rfp_documents = load_documents(rfp_paths, "rfp")
response_documents = load_documents(response_paths, "response")

# Print the parsed documents (or perform further processing)
print(f"Parsed {len(rfp_documents)} RFP documents and {len(response_documents)} Response documents.")

# Initialize the ingestion pipeline with batch processing
pipeline = IngestionPipeline(
    transformations=[
        SentenceSplitter(chunk_size=512, chunk_overlap=0),
        TitleExtractor(),
        OpenAIEmbedding()
    ]
)

# Run the pipeline to create nodes
rfp_nodes = pipeline.run(documents=rfp_documents)
response_nodes = pipeline.run(documents=response_documents)

# Build the vector store indexes
rfp_index = VectorStoreIndex(rfp_nodes)
response_index = VectorStoreIndex(response_nodes)

# Configure the retrievers with optimized settings
rfp_retriever = VectorIndexRetriever(index=rfp_index, similarity_top_k=400)
response_retriever = VectorIndexRetriever(index=response_index, similarity_top_k=400)

# Create the response synthesizer
response_synthesizer = get_response_synthesizer()

# Create the retriever query engines
rfp_query_engine = RetrieverQueryEngine(
    retriever=rfp_retriever,
    response_synthesizer=response_synthesizer
)

response_query_engine = RetrieverQueryEngine(
    retriever=response_retriever,
    response_synthesizer=response_synthesizer
)

# Function to select the correct retriever based on the query
def select_retriever(query):
    if "response" in query.lower() or "Q&A" in query.lower():
        return response_query_engine
    return rfp_query_engine

# Create a custom query engine that selects the correct retriever
class CustomQueryEngine:
    def __init__(self, rfp_query_engine, response_query_engine):
        self.rfp_query_engine = rfp_query_engine
        self.response_query_engine = response_query_engine

    def query(self, query_text):
        query_engine = select_retriever(query_text)
        response = query_engine.query(query_text)
        return response # Use response directly from RetrieverQueryEngine

# Initialize the custom query engine
query_engine = CustomQueryEngine(rfp_query_engine, response_query_engine)

from IPython.display import Markdown, display
# Function to display responses in boxes
def display_in_box(response, title="Response"):
    display(Markdown(f"""
<div style="border: 2px solid #000; padding: 10px; margin: 10px; border-radius: 5px;">
    <strong>{title}</strong><br>
    {response}
</div>
"""))

# Example queries
response_1 = query_engine.query("Provide a detailed overview of the key deliverables and scope outlined in the American Airlines RFP.")
response_2 = query_engine.query("Summarize the key points and proposed solutions provided in the response to the American Airlines RFP.")
response_3 = query_engine.query("Detail the project timeline, including key milestones and deadlines, as specified in the UMichigan RFP.")
response_4 = query_engine.query("Explain the strategic approach and proposed implementation plan detailed in the response to the Peloton RFP.")
response_5 = query_engine.query("Outline the proposed architecture and technological solutions included in the response to the Appfire RFP.")
response_6 = query_engine.query("Provide a breakdown of the financial and technical proposals included in the response to the Nestle RFP.")
response_7 = query_engine.query("List and explain the key questions and answers provided in the Q&A section of the response to the Nestle RFP.")
response_8 = query_engine.query("Identify and describe the core capabilities and service offerings required by the American Airlines RFP.")
response_9 = query_engine.query("Highlight the critical questions raised by Nestle in their response and how they were addressed.")
response_10 = query_engine.query("List and describe the enterprise architecture tools recommended in the response to the American Airlines RFP, including their intended use.")
response_11 = query_engine.query("Detail the key questions posed in the UMichigan RFP response and the context in which they were asked.")
response_12 = query_engine.query("Provide the detailed response given by UMichigan regarding the migration specifics for each Jira instance, including project count, issue volume, user metrics, and attachment sizes.")
response_13 = query_engine.query("Explain the proposed implementation timeline in the Appfire RFP response, including phases and expected completion dates.")
response_14 = query_engine.query("Describe the scope, objectives, and key requirements outlined in the NLB RFP.")
response_15 = query_engine.query("Summarize the strategic solutions and proposed actions in the response to the NLB RFP.")
response_16 = query_engine.query("Elaborate on the key strategies, deliverables, and pricing structure proposed in the response to Macy's RFP.")
response_17 = query_engine.query("Detail the pricing structure, roles, and key deliverables proposed in the Jira Confluence Implementation Bid included in Macy's RFP response.")

# Display responses
display_in_box(response_1, title="Response 1")
display_in_box(response_2, title="Response 2")
display_in_box(response_3, title="Response 3")
display_in_box(response_4, title="Response 4")
display_in_box(response_5, title="Response 5")
display_in_box(response_6, title="Response 6")
display_in_box(response_7, title="Response 7")
display_in_box(response_8, title="Response 8")
display_in_box(response_9, title="Response 9")
display_in_box(resonse_10, title="Response 10")
display_in_box(response_11, title="Response 11")
display_in_box(response_12, title="Response 12")
display_in_box(response_13, title="Response 13")
display_in_box(response_14, title="Response 14")
display_in_box(response_15, title="Response 15")
display_in_box(response_16, title="Response 16")
display_in_box(response_17, title="Response 17")

response_18 = query_engine.query("What is the current state of Jira/Confluence at Macy's Response")
display_in_box(response_18, title="Response 18")
response_19 = query_engine.query("Provide all the roles and pricing.. monthly deliverables, details and cost Macy's Response")
display_in_box(response_19, title="Response 19")
response_20 = query_engine.query("Provide some key approaches, enviroment configurations and key deliverables in Macy's Response")
display_in_box(response_20, title="Response 20")

response_21 = query_engine.query("Provide exact JIRA/Confluence environment specifications detailed in the Macy's Response.. provde exact versions and configs")
display_in_box(response_21, title="Response 21")

response_22 = query_engine.query("Provide exact pricing structure (with prices and roles) in the Nestle Response")
display_in_box(response_22, title="Response 22")

response_23 = query_engine.query("Total Project cost for the Shurz Communication Response. provide a breakdown")
display_in_box(response_23, title="Response 23")

response_24 = query_engine.query("Talk about the implementation approach detailed in the Schurz Communication Response")
display_in_box(response_24, title="Response 24")

response_25 = query_engine.query("Talk about the Appfire Response phases and details")
display_in_box(response_25, title="Response 25")

response_26 = query_engine.query("Provide information about the Etilasat RFP")
display_in_box(response_26, title="Response 26")

response_27 = query_engine.query("What is the Sandia RFQ about")
display_in_box(response_27, title="Response 27")

pip install flask-cors

from flask import Flask, jsonify, request
from flask_cors import CORS
from pyngrok import ngrok

app = Flask(__name__)
CORS(app)

# Setup ngrok tunnel
ngrok.kill()
ngrok.set_auth_token("2jM6x5JTDto589dnwX15h6enC7x_4Vddk6wGRXe8Bd5sxoa4q")
public_url = ngrok.connect(5000)
print("Your public URL is:", public_url)

# Your existing setup for LlamaParse, indexes, etc. goes here...

@app.route('/query', methods=['POST'])
def handle_query():
    data = request.json
    query = data.get('query')

    # Process the query using the CustomQueryEngine
    response = query_engine.query(query)
    print(response.response)

    # Since 'response' is not iterable, we need to handle it differently
    response_data = {
        'response_text': response.response # Assuming this is where the text is
        # Add other necessary fields if needed
    }

    return jsonify(response_data)

if 'get_query_logs' not in app.view_functions:
    @app.route('/logs', methods=['GET'])
    def get_query_logs():
        with open('query_logs.log', 'r') as f:
            logs = f.readlines()
        return jsonify({'logs': logs})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
